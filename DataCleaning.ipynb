{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T01:10:55.599121Z",
     "iopub.status.busy": "2023-02-15T01:10:55.598199Z",
     "iopub.status.idle": "2023-02-15T01:10:55.608358Z",
     "shell.execute_reply": "2023-02-15T01:10:55.607395Z",
     "shell.execute_reply.started": "2023-02-15T01:10:55.599081Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "from random import sample\n",
    "from sklearn.utils import shuffle\n",
    "import re          \n",
    "import zipfile     \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from PIL import ImageFile   \n",
    "import random  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code loads a dataset from a CSV file, and then checks for and removes any rows that correspond to files with corrupted data. The corrupted data is assumed to be stored in a zip archive, and the code uses regex to extract the IDs of the corrupted files from the filenames. Once the IDs of the corrupted files are identified, the corresponding rows in the DataFrame are removed, and the cleaned dataset is written back to the original CSV file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the csv file\n",
    "df = pd.read_csv('all_data_info.csv')\n",
    "\n",
    "# Load the zip archive containing replacement files\n",
    "archive = zipfile.ZipFile('replacements_for_corrupted_files.zip', 'r')\n",
    "\n",
    "# Create a set of IDs for corrupted files\n",
    "corrupted_ids = set()\n",
    "\n",
    "# Loop through all files in the zip archive and extract the IDs\n",
    "# Only add IDs to the set if they contain at least one number\n",
    "for item in archive.namelist():\n",
    "    ID = re.sub(\"[^0-9]\", \"\", item)\n",
    "    if ID != \"\":\n",
    "        corrupted_ids.add(ID)\n",
    "\n",
    "# Create a list of indices for rows to be dropped from the DataFrame\n",
    "drop_idx = []\n",
    "\n",
    "# Loop through all rows in the DataFrame and check if their ID is in the set of corrupted IDs\n",
    "# If the ID is found, add the row index to the list of indices to be dropped\n",
    "for index, row in df.iterrows():\n",
    "    id_check = re.sub(\"[^0-9]\", \"\", row['new_filename'])\n",
    "    if id_check in corrupted_ids:\n",
    "        drop_idx.append(index)\n",
    "\n",
    "# Drop the rows with indices in the drop_idx list from the DataFrame\n",
    "df = df.drop(drop_idx)\n",
    "\n",
    "# Delete the file if it already exists\n",
    "if os.path.exists('all_data_info_1.csv'):\n",
    "    os.remove('all_data_info_1.csv')\n",
    "    \n",
    "# Write the cleaned DataFrame back to the csv file\n",
    "df.to_csv('all_data_info_1.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T01:11:01.228737Z",
     "iopub.status.busy": "2023-02-15T01:11:01.228319Z",
     "iopub.status.idle": "2023-02-15T01:11:01.255104Z",
     "shell.execute_reply": "2023-02-15T01:11:01.254216Z",
     "shell.execute_reply.started": "2023-02-15T01:11:01.228694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>pixelsx</th>\n",
       "      <th>pixelsy</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>source</th>\n",
       "      <th>style</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_group</th>\n",
       "      <th>in_train</th>\n",
       "      <th>new_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>15530.0</td>\n",
       "      <td>6911.0</td>\n",
       "      <td>9201912.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Uriel</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>102257.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>14559.0</td>\n",
       "      <td>6866.0</td>\n",
       "      <td>8867532.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Vir Heroicus Sublimis</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>75232.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1756681.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>32145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1942046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>20304.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1526212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>836.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist    date     genre  pixelsx  pixelsy  size_bytes   source  \\\n",
       "0  Barnett Newman  1955.0  abstract  15530.0   6911.0   9201912.0  wikiart   \n",
       "1  Barnett Newman  1950.0  abstract  14559.0   6866.0   8867532.0  wikiart   \n",
       "2     kiri nichol  2013.0       NaN   9003.0   9004.0   1756681.0      NaN   \n",
       "3     kiri nichol  2013.0       NaN   9003.0   9004.0   1942046.0      NaN   \n",
       "4     kiri nichol  2013.0       NaN   9003.0   9004.0   1526212.0      NaN   \n",
       "\n",
       "                  style                  title artist_group  in_train  \\\n",
       "0  Color Field Painting                  Uriel   train_only      True   \n",
       "1  Color Field Painting  Vir Heroicus Sublimis   train_only      True   \n",
       "2         Neoplasticism                    NaN    test_only     False   \n",
       "3         Neoplasticism                    NaN    test_only     False   \n",
       "4         Neoplasticism                    NaN    test_only     False   \n",
       "\n",
       "  new_filename  \n",
       "0   102257.jpg  \n",
       "1    75232.jpg  \n",
       "2    32145.jpg  \n",
       "3    20304.jpg  \n",
       "4      836.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above code is using the Python's zipfile module to extract the contents of two zip files train_3.zip and test.zip.**\n",
    "\n",
    "**The first block of code uses the with statement and creates a ZipFile object by passing the file path of the train_3.zip file and opens it in read mode ('r'). The extractall() method is then called on this object to extract all the contents of the zip file into the directory named 'train'.**\n",
    "\n",
    "**The second block of code follows a similar pattern, but this time it opens the test.zip file and extracts its contents to a directory named 'test'.**\n",
    "\n",
    "**In summary, these two blocks of code extract the contents of two zip files and store them in two separate directories.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T01:11:01.257156Z",
     "iopub.status.busy": "2023-02-15T01:11:01.256430Z",
     "iopub.status.idle": "2023-02-15T01:15:14.540891Z",
     "shell.execute_reply": "2023-02-15T01:15:14.538711Z",
     "shell.execute_reply.started": "2023-02-15T01:11:01.257116Z"
    }
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(path+'train_2.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(path+'test.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 21733.jpg as it has extra channels other than RGB.\n",
      "Skipping 22580.jpg as it has extra channels other than RGB.\n",
      "Skipping 24241.jpg as it has extra channels other than RGB.\n",
      "Skipping 27735.jpg as it has extra channels other than RGB.\n",
      "Skipping 2881.jpg as it has extra channels other than RGB.\n",
      "Skipping 29815.jpg as it has extra channels other than RGB.\n",
      "Skipping 29854.jpg as it has extra channels other than RGB.\n"
     ]
    }
   ],
   "source": [
    "# iterate over all the images in the \"train/train_3\" folder\n",
    "for filename in os.listdir(\"train/train_2\"):\n",
    "    # open the image and check if it has extra channels\n",
    "    image =  Image.open(os.path.join(\"train/train_2\", filename)) \n",
    "    if len(image.getbands()) > 3:\n",
    "        print(f\"Skipping {filename} as it has extra channels other than RGB.\")\n",
    "        image.close()\n",
    "        os.remove(os.path.join(\"train/train_2\", filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▋                                                            | 4668/23815 [00:01<00:10, 1805.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 25416.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████████▋                                                        | 6166/23815 [00:06<00:40, 430.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 30623.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████████▉                                                       | 6569/23815 [00:08<00:49, 349.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 32071.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████████████████▉                                                      | 6862/23815 [00:09<00:58, 289.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 33273.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▎                                                   | 7599/23815 [00:11<00:52, 306.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 35962.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|██████████████████████████▋                                                 | 8347/23815 [00:14<00:51, 300.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 39101.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████████▍                                             | 9552/23815 [00:18<00:47, 303.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 44017.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████▊                                        | 11053/23815 [00:23<00:42, 297.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 49778.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████████████████████                                        | 11147/23815 [00:24<00:41, 303.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 5018.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|█████████████████████████████████████                                      | 11784/23815 [00:26<00:41, 286.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 52742.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████▍                                    | 12188/23815 [00:28<00:41, 283.42it/s]C:\\Users\\YASSIN\\.conda\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py:3035: DecompressionBombWarning: Image size (133026477 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n",
      " 62%|██████████████████████████████████████████████▏                            | 14672/23815 [00:37<00:30, 303.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 64004.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████████▌                        | 16040/23815 [00:41<00:26, 290.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 69423.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████▊                        | 16135/23815 [00:42<00:25, 306.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 69828.jpg as it has extra channels other than RGB.\n",
      "Skipping 70061.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|█████████████████████████████████████████████████████▎                     | 16917/23815 [00:44<00:23, 298.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 72972.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████▏                   | 17523/23815 [00:46<00:21, 297.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 75551.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████▌                  | 17962/23815 [00:48<00:19, 307.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 77299.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|██████████████████████████████████████████████████████████████████▏        | 21026/23815 [00:58<00:09, 298.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 89073.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████       | 21615/23815 [01:01<00:08, 269.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 91447.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████████████████████████████████████████████████████████████████▏     | 21963/23815 [01:02<00:05, 311.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 92799.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████▌     | 22086/23815 [01:02<00:06, 280.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 93262.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████████████████████████████████████████████▉     | 22207/23815 [01:03<00:05, 290.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 93738.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|██████████████████████████████████████████████████████████████████████▋    | 22442/23815 [01:03<00:05, 258.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 94705.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████▊| 23773/23815 [01:08<00:00, 298.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 99592.jpg as it has extra channels other than RGB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 23815/23815 [01:08<00:00, 345.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# iterate over all the images in the \"train/train_3\" folder\n",
    "for filename in tqdm(os.listdir(\"test/test\")):\n",
    "    # open the image and check if it has extra channels\n",
    "    try:\n",
    "        image =  Image.open(os.path.join(\"test/test\", filename)) \n",
    "    except:\n",
    "        os.remove(os.path.join(\"test/test\", filename))\n",
    "        continue\n",
    "    if len(image.getbands()) > 3:\n",
    "        print(f\"Skipping {filename} as it has extra channels other than RGB.\")\n",
    "        image.close()\n",
    "        os.remove(os.path.join(\"test/test\", filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8469/8469 [00:09<00:00, 850.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 51/51 [00:00<00:00, 5663.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from struct import unpack\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "\n",
    "marker_mapping = {\n",
    "    0xffd8: \"Start of Image\",\n",
    "    0xffe0: \"Application Default Header\",\n",
    "    0xffdb: \"Quantization Table\",\n",
    "    0xffc0: \"Start of Frame\",\n",
    "    0xffc4: \"Define Huffman Table\",\n",
    "    0xffda: \"Start of Scan\",\n",
    "    0xffd9: \"End of Image\"\n",
    "}\n",
    "\n",
    "\n",
    "class JPEG:\n",
    "    def __init__(self, image_file):\n",
    "        with open(image_file, 'rb') as f:\n",
    "            self.img_data = f.read()\n",
    "    \n",
    "    def decode(self):\n",
    "        data = self.img_data\n",
    "        while(True):\n",
    "            marker, = unpack(\">H\", data[0:2])\n",
    "            # print(marker_mapping.get(marker))\n",
    "            if marker == 0xffd8:\n",
    "                data = data[2:]\n",
    "            elif marker == 0xffd9:\n",
    "                return\n",
    "            elif marker == 0xffda:\n",
    "                data = data[-2:]\n",
    "            else:\n",
    "                lenchunk, = unpack(\">H\", data[2:4])\n",
    "                data = data[2+lenchunk:]            \n",
    "            if len(data)==0:\n",
    "                break        \n",
    "\n",
    "\n",
    "bads = []\n",
    "\n",
    "for img in tqdm(os.listdir(\"train/train_2\")):\n",
    "    image = os.path.join(\"train/train_2\",img)\n",
    "    image = JPEG(image) \n",
    "    try:\n",
    "        image.decode()   \n",
    "    except:\n",
    "        bads.append(img)\n",
    "\n",
    "\n",
    "for name in tqdm(bads):\n",
    "    os.remove(os.path.join(\"train/train_2\",name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 23789/23789 [01:31<00:00, 260.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 119/119 [00:00<00:00, 5965.94it/s]\n"
     ]
    }
   ],
   "source": [
    "bads = []\n",
    "\n",
    "for img in tqdm(os.listdir(\"test/test\")):\n",
    "    image = os.path.join(\"test/test\",img)\n",
    "    image = JPEG(image) \n",
    "    try:\n",
    "        image.decode()   \n",
    "    except:\n",
    "        bads.append(img)\n",
    "\n",
    "\n",
    "for name in tqdm(bads):\n",
    "    os.remove(os.path.join(\"test/test\",name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each file in the folder\n",
    "for filename in os.listdir(\"train/train_2\"):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'): # change extensions as needed\n",
    "        filepath = os.path.join(\"train/train_2\", filename)\n",
    "        \n",
    "        # open the image and get its mode and bands\n",
    "        with Image.open(filepath) as img:\n",
    "            mode = img.mode\n",
    "            bands = img.getbands()\n",
    "            \n",
    "            # check if the image is grayscale or has extra channels with zero information\n",
    "            if (mode == 'L') or (len(bands) > 3 and bands[-1] == 'A'):\n",
    "                t=True\n",
    "            else:\n",
    "                t=False\n",
    "        if t: os.remove(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each file in the folder\n",
    "for filename in os.listdir(\"test/test\"):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'): # change extensions as needed\n",
    "        filepath = os.path.join(\"test/test\", filename)\n",
    "        \n",
    "        # open the image and get its mode and bands\n",
    "        with Image.open(filepath) as img:\n",
    "            mode = img.mode\n",
    "            bands = img.getbands()\n",
    "            \n",
    "            # check if the image is grayscale or has extra channels with zero information\n",
    "            if (mode == 'L') or (len(bands) > 3 and bands[-1] == 'A'):\n",
    "                t=True\n",
    "            else:\n",
    "                t=False\n",
    "        if t: os.remove(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This code defines a function called del_image that takes an image file path as an argument. It reads the image file, decodes and resizes the image, and preprocesses the image using the VGG16 model. If an exception is raised during this process, the function prints a message indicating that the image is corrupted and then removes the file using the os.remove() function. The purpose of this function is to remove corrupted images from the dataset, which can cause errors during training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T01:23:16.112074Z",
     "iopub.status.busy": "2023-02-15T01:23:16.111030Z",
     "iopub.status.idle": "2023-02-15T01:23:16.118902Z",
     "shell.execute_reply": "2023-02-15T01:23:16.117598Z",
     "shell.execute_reply.started": "2023-02-15T01:23:16.112030Z"
    }
   },
   "outputs": [],
   "source": [
    "def del_image(image_path):\n",
    "    try:\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, (224, 224))\n",
    "        image = tf.keras.applications.vgg16.preprocess_input(image)\n",
    "    except:\n",
    "        print(f'Removing corrupted image: {image_path}')\n",
    "        os.remove(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, This code deletes corrupted images in a given folder train/train_3 by calling the del_image function on each file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T01:33:50.517891Z",
     "iopub.status.busy": "2023-02-15T01:33:50.517443Z",
     "iopub.status.idle": "2023-02-15T01:37:26.917567Z",
     "shell.execute_reply": "2023-02-15T01:37:26.916487Z",
     "shell.execute_reply.started": "2023-02-15T01:33:50.517849Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8338/8338 [02:15<00:00, 61.59it/s]\n"
     ]
    }
   ],
   "source": [
    "train_folder = 'train/train_2'\n",
    "for filename in tqdm(os.listdir(train_folder)):\n",
    "        image_path = os.path.join(train_folder, filename)\n",
    "        del_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 23450/23450 [07:08<00:00, 54.70it/s]\n"
     ]
    }
   ],
   "source": [
    "train_folder = 'test/test'\n",
    "for filename in tqdm(os.listdir(train_folder)):\n",
    "        image_path = os.path.join(train_folder, filename)\n",
    "        del_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-15T01:29:11.769310Z",
     "iopub.status.busy": "2023-02-15T01:29:11.768845Z",
     "iopub.status.idle": "2023-02-15T01:29:11.775410Z",
     "shell.execute_reply": "2023-02-15T01:29:11.774330Z",
     "shell.execute_reply.started": "2023-02-15T01:29:11.769268Z"
    }
   },
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# define input and output directories\n",
    "input_dir = 'train/train_2'\n",
    "output_dir = 'train/train_crop'\n",
    "\n",
    "# define target size for the center crop\n",
    "target_size = (224, 224)\n",
    "\n",
    "# create the output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop through each file in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "        # open the image file\n",
    "        try:\n",
    "            image = Image.open(os.path.join(input_dir, filename))\n",
    "\n",
    "            # calculate the center crop box\n",
    "            width, height = image.size\n",
    "            left = (width - target_size[0]) / 2\n",
    "            top = (height - target_size[1]) / 2\n",
    "            right = (width + target_size[0]) / 2\n",
    "            bottom = (height + target_size[1]) / 2\n",
    "\n",
    "            # crop the image\n",
    "            image = image.crop((left, top, right, bottom))\n",
    "\n",
    "            # save the cropped image to the output directory\n",
    "            image.save(os.path.join(output_dir, filename))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# define input and output directories\n",
    "input_dir = 'test/test'\n",
    "output_dir = 'test/test_crop'\n",
    "\n",
    "# define target size for the center crop\n",
    "target_size = (224, 224)\n",
    "\n",
    "# create the output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# loop through each file in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "        # open the image file\n",
    "        try:\n",
    "            image = Image.open(os.path.join(input_dir, filename))\n",
    "\n",
    "            # calculate the center crop box\n",
    "            width, height = image.size\n",
    "            left = (width - target_size[0]) / 2\n",
    "            top = (height - target_size[1]) / 2\n",
    "            right = (width + target_size[0]) / 2\n",
    "            bottom = (height + target_size[1]) / 2\n",
    "\n",
    "            # crop the image\n",
    "            image = image.crop((left, top, right, bottom))\n",
    "\n",
    "            # save the cropped image to the output directory\n",
    "            image.save(os.path.join(output_dir, filename))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above code crops the images, using centric croping to reduce training complexity**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
